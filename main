# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import library yang diperlukan (NumPy & Pandas)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Path folder dataset
path = "./drive/MyDrive/Colab_File/Dataset/"

# Load file CSV ke dalam NumPy array
train_X = pd.read_csv(path + "train_X.csv", header=None).to_numpy()
train_y = pd.read_csv(path + "train_label.csv", header=None).to_numpy()
test_X  = pd.read_csv(path + "test_X.csv", header=None).to_numpy()
test_y  = pd.read_csv(path + "test_label.csv", header=None).to_numpy()

# Mengubah jadi angka pakai argmax
if train_y.shape[1] > 1:  # berarti one-hot
    train_y = np.argmax(train_y, axis=1)
else:
    train_y = train_y.flatten()

if test_y.shape[1] > 1:
    test_y = np.argmax(test_y, axis=1)
else:
    test_y = test_y.flatten()

# Print bentuk data awal (untuk dataset Train)
print("Train_X shape :", train_X.shape)
print("Train_y shape :", train_y.shape)

# Print bentuk data awal (untuk dataset Test)
print("Test_X shape  :", test_X.shape)
print("Test_y shape  :", test_y.shape)

print("Sebelum scaling:")
print("Min:", np.min(train_X))
print("Max:", np.max(train_X))

# Mengubah nilai piksel menjadi rentang 0 - 1000 (bukan 0 - 255)
train_X = (train_X / 255.0) * 1000.0
test_X  = (test_X / 255.0) * 1000.0

# Memastikan tipe data float (biar aman di operasi dot & gradien)
train_X = train_X.astype(np.float32)
test_X  = test_X.astype(np.float32)

# Mengecek contoh nilai pixel
print("Contoh 10 nilai pertama train_X:", train_X[0][:10])
print("Nilai minimum:", np.min(train_X), "| Nilai maksimum:", np.max(train_X))

# Menentukan ukuran layer
input_size = 784      # 28 x 28
hidden_size = 64
output_size = 10      # kelas angka 0-9

# Inisialisasi bobot (W1, W2) & bias (b1, b2)
W1 = np.random.randn(hidden_size, input_size) * 0.01
b1 = np.zeros((hidden_size, 1))

W2 = np.random.randn(output_size, hidden_size) * 0.01
b2 = np.zeros((output_size, 1))

# Print shape-nya
print("W1 shape:", W1.shape)
print("b1 shape:", b1.shape)
print("W2 shape:", W2.shape)
print("b2 shape:", b2.shape)

# Fungsi ReLU
def relu(Z):
    return np.maximum(0, Z)

# Turunan ReLU
def relu_derivative(Z):
    return (Z > 0).astype(float)

# Fungsi Softmax
def softmax(Z):
    # Z shape: (output_size, jumlah_sampel)
    exp_vals = np.exp(Z - np.max(Z, axis=0, keepdims=True))
    return exp_vals / np.sum(exp_vals, axis=0, keepdims=True)

def forward_pass(X, W1, b1, W2, b2):
    """
    X shape: (m, 784)
    W1: (64, 784)
    b1: (64, 1)
    W2: (10, 64)
    b2: (10, 1)
    """
    # Transpose supaya shape jadi (784, m)
    X_T = X.T

    # Hidden layer
    Z1 = np.dot(W1, X_T) + b1  # shape: (64, m)
    A1 = relu(Z1)              # shape: (64, m)

    # Output layer
    Z2 = np.dot(W2, A1) + b2   # shape: (10, m)
    A2 = softmax(Z2)           # shape: (10, m)

    return Z1, A1, Z2, A2

# Eksekusi
Z1, A1, Z2, A2 = forward_pass(train_X, W1, b1, W2, b2)

print("Z1 shape:", Z1.shape)
print("A1 shape:", A1.shape)
print("Z2 shape:", Z2.shape)
print("A2 shape:", A2.shape)

def to_one_hot(labels, num_classes=10):
    """
    labels shape: (m,)
    return shape: (num_classes, m)
    """
    m = labels.shape[0]
    one_hot = np.zeros((num_classes, m))
    one_hot[labels, np.arange(m)] = 1
    return one_hot

def compute_loss(A2, Y_one_hot):
    """
    A2: (10, m)
    Y_one_hot: (10, m)
    """
    m = Y_one_hot.shape[1]
    # Hindari log(0)
    log_probs = np.log(A2 + 1e-12)
    loss = -np.sum(Y_one_hot * log_probs) / m
    return loss

# Mengubah label train jadi one-hot
train_Y_one_hot = to_one_hot(train_y, num_classes=10)

# Menghitung fwd pass lalu loss
Z1, A1, Z2, A2 = forward_pass(train_X, W1, b1, W2, b2)
cost = compute_loss(A2, train_Y_one_hot)
print("Initial cost:", cost)

def backward_pass(X, Y_one_hot, Z1, A1, A2, W1, W2):
    """
    X shape: (m, 784)
    Y_one_hot shape: (10, m)
    """
    m = X.shape[0]
    X_T = X.T  # (784, m)

    # ∂cost/∂Z2
    d_cost_Z2 = A2 - Y_one_hot  # (10, m)

    # ∂cost/∂W2
    d_cost_W2 = (1/m) * np.dot(d_cost_Z2, A1.T)  # (10, 64)

    # ∂cost/∂b2
    d_cost_b2 = (1/m) * np.sum(d_cost_Z2, axis=1, keepdims=True)  # (10, 1)

    # ∂cost/∂Z1
    d_cost_Z1 = np.dot(W2.T, d_cost_Z2) * relu_derivative(Z1)  # (64, m)

    # ∂cost/∂W1
    d_cost_W1 = (1/m) * np.dot(d_cost_Z1, X_T.T)  # (64, 784)

    # ∂cost/∂b1
    d_cost_b1 = (1/m) * np.sum(d_cost_Z1, axis=1, keepdims=True)  # (64, 1)

    return d_cost_W1, d_cost_b1, d_cost_W2, d_cost_b2

# Eksekusi setelah forward pass
dW1, db1, dW2, db2 = backward_pass(train_X, train_Y_one_hot, Z1, A1, A2, W1, W2)

print("d_cost_W1 shape:", dW1.shape)
print("d_cost_b1 shape:", db1.shape)
print("d_cost_W2 shape:", dW2.shape)
print("d_cost_b2 shape:", db2.shape)

learning_rate = 0.001
epochs = 100  # ubah kalau kurang akurat (makin tinggi, makin makan RAM:v)

for epoch in range(epochs):
    # Forward pass
    Z1, A1, Z2, A2 = forward_pass(train_X, W1, b1, W2, b2)

    # Hitung loss
    cost = compute_loss(A2, train_Y_one_hot)

    # Backpropagation
    dW1, db1, dW2, db2 = backward_pass(train_X, train_Y_one_hot, Z1, A1, A2, W1, W2)

    # Update parameter
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2

    # Print cost tiap epoch
    print(f"Epoch {epoch+1}/{epochs} - Cost: {cost:.4f}")

def predict_single_image(index, X, W1, b1, W2, b2):
    """
    Ambil 1 sampel dari X sesuai index,
    lakukan forward pass,
    kembalikan prediksi kelas dan juga gambar 28x28.
    """
    # 1. Ambil satu baris (shape 784,)
    x_sample = X[index]  # (784,)

    # 2. Bentuk ulang ke (784, 1) supaya cocok ke forward pass
    x_col = x_sample.reshape(-1, 1)

    # 3. Forward pass manual
    Z1 = np.dot(W1, x_col) + b1     # (64,1)
    A1 = relu(Z1)                   # (64,1)
    Z2 = np.dot(W2, A1) + b2        # (10,1)
    A2 = softmax(Z2)                # (10,1)

    # 4. Prediksi kelas
    predicted_label = np.argmax(A2, axis=0)[0]

    # 5. Kembalikan juga data 28x28 untuk visual
    image_28x28 = x_sample.reshape(28, 28)
    return predicted_label, image_28x28

# Ganti index
change = 444

idx = change
pred_label, img_matrix = predict_single_image(idx, train_X, W1, b1, W2, b2)

print("Prediksi model untuk index", idx, "=", pred_label)

# Tampilkan matrix (28x28) dan gambarnya
plt.figure(figsize=(4,4))
plt.imshow(img_matrix, cmap='gray')
plt.title(f"Predicted: {pred_label}")
plt.axis('off')
plt.show()

idx = change
_, img_matrix = predict_single_image(idx, train_X, W1, b1, W2, b2)

# Cetak matrix 28x28 versi angka
for row in img_matrix:
    print(" ".join([f"{int(val):4d}" for val in row]))

idx = change
_, img_matrix = predict_single_image(idx, train_X, W1, b1, W2, b2)

plt.figure(figsize=(6,6))
plt.imshow(img_matrix, cmap='gray')

# Tambah angka di setiap sel
for i in range(28):
    for j in range(28):
        plt.text(j, i, str(int(img_matrix[i][j])), ha='center', va='center', fontsize=6)

plt.title("Matrix Pixel 28x28")
plt.axis('off')
plt.show()

def accuracy(A2, true_labels):
    predictions = np.argmax(A2, axis=0)
    return np.mean(predictions == true_labels) * 100

Z1, A1, Z2, A2 = forward_pass(train_X, W1, b1, W2, b2)
acc = accuracy(A2, train_y)
print(f"Train Accuracy: {acc:.2f}%")
